<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://Or0kit.github.io</id>
    <title>Or0kit • Posts by &#34;scrapy&#34; tag</title>
    <link href="https://Or0kit.github.io" />
    <updated>2020-12-28T09:47:19.000Z</updated>
    <category term="Algolia" />
    <category term="同义词替换" />
    <category term="Drozer" />
    <category term="xpath" />
    <category term="win32api" />
    <category term="WOW64" />
    <category term="windows消息机制" />
    <category term="虚拟内存" />
    <category term="jsDelivr" />
    <category term="First blog" />
    <category term="markdown 学习" />
    <category term="Android" />
    <category term="数论基础" />
    <category term="替换密钥" />
    <category term="ADB" />
    <category term="雷电模拟器" />
    <category term="Hadoop" />
    <category term="IDA" />
    <category term="Windows逆向" />
    <category term="SSH隧道" />
    <category term="url" />
    <category term="http" />
    <category term="Linux" />
    <category term="Nginx" />
    <category term="CentOS7配置vsftp" />
    <category term="Psad" />
    <category term="fwsnort" />
    <category term="应急响应" />
    <category term="x86汇编指令" />
    <category term="PE课后作业" />
    <category term="MFC" />
    <category term="PE查看器" />
    <category term="PE结构" />
    <category term="DOS头属性说明" />
    <category term="标准PE头属性说明" />
    <category term="扩展PE头属性说明" />
    <category term="节表属性说明" />
    <category term="空白区添加代码" />
    <category term="RVA与FOA" />
    <category term="合并节" />
    <category term="注入" />
    <category term="导入表注入" />
    <category term="导出表" />
    <category term="导入表" />
    <category term="扩大节" />
    <category term="新增节" />
    <category term="移动NT头" />
    <category term="移动导出表" />
    <category term="移动重定位表" />
    <category term="重定位表" />
    <category term="静态链接库" />
    <category term="动态链接库" />
    <category term="句柄" />
    <category term="逆向" />
    <category term="IDA学习" />
    <category term="静态分析基础" />
    <category term="动态分析技术基础" />
    <category term="恶意代码分析实战入门" />
    <category term="加壳" />
    <category term="脱壳" />
    <category term="C++壳" />
    <category term="ESP寻址" />
    <category term="定位Win32窗口回调函数" />
    <category term="HOOK攻防" />
    <category term="瞬时HOOK过检测" />
    <category term="INLINE-HOOK" />
    <category term="IAT HOOK" />
    <category term="INLINE HOOK" />
    <category term="进程监控" />
    <category term="模块隐藏" />
    <category term="进程通信" />
    <category term="tlhelp32.h" />
    <category term="进程遍历" />
    <category term="模块遍历" />
    <category term="外挂原理" />
    <category term="DLL注入之进程间通信" />
    <category term="TEB" />
    <category term="PEB" />
    <category term="R3层断链" />
    <category term="Win临界区" />
    <category term="Win事件" />
    <category term="线程同步" />
    <category term="Win互斥体" />
    <category term="内存映射文件" />
    <category term="内存映射共享" />
    <category term="写拷贝" />
    <category term="Win子窗口控件" />
    <category term="win32文件函数" />
    <category term="代码注入" />
    <category term="窗口程序" />
    <category term="消息机制" />
    <category term="消息类型" />
    <category term="私有内存" />
    <category term="共享内存" />
    <category term="设备对象" />
    <category term="DC设备上下文" />
    <category term="图形对象" />
    <category term="创建线程" />
    <category term="线程控制" />
    <category term="线程相关API" />
    <category term="线程上下文" />
    <category term="CONTEXT结构体" />
    <category term="物理内存" />
    <category term="Windows进程" />
    <category term="句柄表" />
    <category term="远程线程函数" />
    <category term="远程线程" />
    <category term="DLL注入" />
    <category term="DLL注入相关函数" />
    <category term="WinMain函数" />
    <category term="调用约定" />
    <category term="我的GetProcAddress" />
    <category term="资源文件" />
    <category term="消息断点" />
    <category term="通用控件" />
    <category term="WM_NOTIFY消息类型" />
    <category term="CobaltStrike" />
    <category term="Apeache" />
    <category term="Nmap" />
    <category term="php" />
    <category term="guestbook" />
    <category term="SQLmap" />
    <category term="apache" />
    <category term="log" />
    <category term="mysql主键" />
    <category term="CSRF" />
    <category term="SSRF" />
    <category term="业务逻辑漏洞" />
    <category term="xss" />
    <category term="webshell流量特征" />
    <category term="虚拟网卡" />
    <category term="RedTeam" />
    <category term="python" />
    <category term="SSH" />
    <category term="python文件读取" />
    <category term="数据分析" />
    <category term="socket" />
    <category term="数据库编程" />
    <category term="python内置属性" />
    <category term="scrapy" />
    <category term="测试" />
    <category term="BHP" />
    <category term="Python的import功能" />
    <category term="木马" />
    <category term="button" />
    <category term="multiprocessing" />
    <category term="threading" />
    <category term="单选框" />
    <category term="复选框件" />
    <category term="Edit" />
    <category term="Combo Box" />
    <category term="Tab" />
    <category term="ListCtrl" />
    <category term="MFC的本质" />
    <category term="MFC的层次结构图" />
    <category term="手动创建一个MFC程序" />
    <category term="MFC的初始化过程" />
    <category term="MFC运行时类型识别" />
    <category term="关键字static" />
    <category term="关键字const" />
    <category term="MFC动态创建" />
    <category term="MFC消息映射" />
    <category term="结构体AFX_MSGMAP_ENTRY" />
    <category term="结构体AFX_MSGM" />
    <category term="MFC的三大类消息" />
    <category term="数据传输" />
    <category term="ini文件的读写" />
    <category term="非可变序列算法" />
    <category term="可变序列算法" />
    <category term="排序算法" />
    <category term="迭代器" />
    <category term="使用自定义对象" />
    <category term="0环与3环的通信（常规方法）" />
    <category term="内核空间" />
    <category term="内核模块" />
    <category term="遍历内核模块" />
    <category term="定位未导出函数PspTiminateProcess" />
    <category term="内核编程基础" />
    <category term="ANSI_STRING" />
    <category term="UNICODE_STRING" />
    <category term="内核内存" />
    <category term="上下文环境" />
    <category term="中断请求级别" />
    <category term="链表" />
    <category term="自旋锁" />
    <category term="注册表" />
    <category term="地址空间" />
    <category term="文件操作" />
    <category term="线程与事件" />
    <category term="内核重载" />
    <category term="配置VS2019+WDK10" />
    <category term="第一个驱动程序" />
    <category term="驱动调试" />
    <category term="调试驱动程序" />
    <category term="OpenSCManager" />
    <category term="CreateService" />
    <category term="APC的本质" />
    <category term="APC的备用队列" />
    <category term="线性地址的管理" />
    <category term="VAD树" />
    <category term="_MMVAD" />
    <category term="_MMVAD_FLAGS" />
    <category term="VirtualAlloc" />
    <category term="MEM_COMMIT与MEM_RESERVE" />
    <category term="malloc" />
    <category term="堆内存" />
    <category term="栈内存" />
    <category term="全局区内存" />
    <category term="共享物理页" />
    <category term="共享文件" />
    <category term="LoadLibrary的本质" />
    <category term="MmAddPhysicalMemoryEx" />
    <category term="缺页异常" />
    <category term="消息队列" />
    <category term="PsConvertToGuiThread" />
    <category term="win32k.sys" />
    <category term="GUI线程" />
    <category term="窗口程序的创建" />
    <category term="消息循环" />
    <category term="临界区" />
    <category term="KPCR结构体" />
    <category term="模拟线程切换" />
    <category term="模拟挂起与恢复函数" />
    <category term="等待链表" />
    <category term="调度链表" />
    <category term="ETHREAD" />
    <category term="KTHREAD" />
    <category term="进程的创建" />
    <category term="获取当前进程" />
    <category term="EPROCESS" />
    <category term="KPROCESS" />
    <category term="2-9-9-12分页" />
    <category term="PAE" />
    <category term="PDPTE" />
    <category term="PDE" />
    <category term="PTE" />
    <category term="XD标志位" />
    <category term="逆向分析MmIsAddressValid函数(2-9-9-12)" />
    <category term="PWT" />
    <category term="PDT" />
    <category term="TLB" />
    <category term="CPU缓存" />
    <category term="INVLPG指令" />
    <category term="全局页" />
    <category term="ShadowWalker" />
    <category term="中断" />
    <category term="异常" />
    <category term="CLI指令" />
    <category term="STI指令" />
    <category term="INT2" />
    <category term="INT8" />
    <category term="中断门描述符" />
    <category term="IDT" />
    <category term="提权" />
    <category term="跨段跳转流程" />
    <category term="JMP FAR指令" />
    <category term="TSS" />
    <category term="任务门" />
    <category term="LDT段描述符" />
    <category term="LDT" />
    <category term="CR0" />
    <category term="CR2" />
    <category term="CR4" />
    <category term="段寄存器结构" />
    <category term="段描述符" />
    <category term="段选择子" />
    <category term="GDT表" />
    <category term="CRL" />
    <category term="DPL" />
    <category term="RPL" />
    <category term="调用门" />
    <category term="调用门描述符" />
    <category term="逆向分析MmIsAddressValid函数" />
    <category term="CALL与CALL FAR" />
    <category term="error C2143" />
    <category term="error C2275" />
    <category term="陷阱门描述符" />
    <category term="页目录表基址" />
    <category term="页表的基址" />
    <category term="0地址执行ShellCode" />
    <category term="10-10-12分页" />
    <category term="PDE_PTE" />
    <category term="物理页" />
    <category term="SSDT HOOK" />
    <category term="OpenProcess" />
    <category term="系统服务表" />
    <category term="SSDT" />
    <category term="SSDT HOOK隐藏" />
    <category term="API进出内核" />
    <category term="系统调用阶段总结" />
    <category term="网络安全法" />
    <category term="ASCII" />
    <category term="GBK" />
    <category term="ANSI" />
    <category term="Unicode" />
    <category term="UTF-8" />
    <category term="URL 编码/解码" />
    <category term="十进制" />
    <category term="二进制" />
    <category term="十六进制" />
    <category term="内存" />
    <category term="编写ShellCode实现IAT HOOK" />
    <category term="ShellCode原则" />
    <category term="加载图标" />
    <category term="提取图标" />
    <category term="资源表" />
    <category term="傀儡进程加密壳" />
    <category term="ZwUnmapViewOfSection函数" />
    <category term="HTML" />
    <category term="文件包含" />
    <category term="sql注入" />
    <category term="MFC命令传递" />
    <category term="远控界面编写" />
    <category term="STL" />
    <category term="Vector容器" />
    <category term="Deque容器" />
    <category term="List容器" />
    <category term="Set容器" />
    <category term="Multiset容器" />
    <category term="Map容器" />
    <category term="Multimap容器" />
    <category term="Stack容器" />
    <category term="Queue容器" />
    <category term="priority_queue容器" />
    <category term="经典定长指令" />
    <category term="经典变长指令" />
    <category term="指令前缀" />
    <category term="KAPC" />
    <category term="QueueUserAPC" />
    <category term="NtQueueApcThread" />
    <category term="KeInitializeApc" />
    <category term="KeInsertQueueApc" />
    <category term="KiInsertQueueApc" />
    <category term="进程句柄表" />
    <category term="全局句柄表" />
    <category term="消息队列与线程" />
    <category term="Windows线程切换" />
    <category term="KiSwapContext" />
    <category term="SwapContext" />
    <category term="时钟中断" />
    <category term="时间片管理" />
    <category term="线程切换与TSS" />
    <category term="线程切换与FS" />
    <category term="线程切换与线程优先级" />
    <category term="快速调用" />
    <category term="中断调用" />
    <category term="分析ReadProcessMemory" />
    <category term="KiFastSystemCall" />
    <category term="KiIntSystemCall" />
    <category term="重写3环" />
    <category term="文件上传" />
    <category term="隐藏驱动" />
    <category term="IopLoadDriver" />
    <category term="延迟过程调用" />
    <category term="进程挂靠" />
    <category term="跨进程读写内存" />
    <category term="APC" />
    <category term="逆向分析NtReadVirtualMemory" />
    <category term="逆向分析NtWriteVIrtualMemory" />
    <category term="payload" />
    <category term="AD-Attack-Defense" />
    <category term="sysenter指令" />
    <category term="KiFastCallEntry函数" />
    <category term="KiSystemService函数" />
    <category term="Trap_Frame" />
    <category term="web安全" />
    <category term="Pentest" />
    <entry>
        <id>https://or0kit.github.io/Programming/Python/scrapy%E6%A1%86%E6%9E%B6/</id>
        <title>scrapy框架</title>
        <link rel="alternate" href="https://or0kit.github.io/Programming/Python/scrapy%E6%A1%86%E6%9E%B6/"/>
        <content type="html">&lt;h1 id=&#34;什么是scrapy&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#什么是scrapy&#34;&gt;#&lt;/a&gt; 什么是 scrapy&lt;/h1&gt;
&lt;font color=&#34;#00CED1&#34;&gt;
&lt;p&gt;Scrapy 是一个为了爬取网站数据，提取结构性数据而编写的应用框架。可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。其最初是为了页面抓取 (更确切来说，网络抓取) 所设计的，也可以应用在获取 API 所返回的数据 (例如 Amazon Associates Web Services ) 或者通用的网络爬虫。Scrapy 其实是 Search+Python。Scrapy 使用 Twisted 这个异步网络库来处理网络通讯，架构清晰，并且包含了各种中间件接口，可以灵活的完成各种需求。&lt;/p&gt;
&lt;/font&gt;
&lt;h1 id=&#34;scrapy架构&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#scrapy架构&#34;&gt;#&lt;/a&gt; scrapy 架构&lt;/h1&gt;
&lt;h2 id=&#34;scrapy整体结构&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#scrapy整体结构&#34;&gt;#&lt;/a&gt; Scrapy 整体结构&lt;/h2&gt;
&lt;font color=&#34;#00CED1&#34;&gt;
&lt;p&gt;&lt;strong&gt;1、引擎 (Scrapy Engine)&lt;/strong&gt;&lt;br /&gt;
 用来处理整个系统的数据流处理，触发事务。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2、调度器 (Scheduler)&lt;/strong&gt;&lt;br /&gt;
 用来接受引擎发过来的请求，压入队列中，并在引擎再次请求的时候返回。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3、下载器 (Downloader)&lt;/strong&gt;&lt;br /&gt;
 用于下载网页内容，并将网页内容返回给蜘蛛。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4、蜘蛛 (Spiders)&lt;/strong&gt;&lt;br /&gt;
 蜘蛛是主要干活的，用它来制订特定域名或网页的解析规则。编写用于分析 response 并提取 item (即获取到的 item) 或额外跟进的 URL 的类。&lt;br /&gt;
每个 spider 负责处理一个特定 (或一些) 网站。蜘蛛的整个抓取流程（周期）是这样的：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;首先获取第一个 URL 的初始请求，当请求返回后调取一个回调函数。第一个请求是通过调用 start_requests () 方法。该方法默认从 start_urls 中的 Url 中生成请求，并执行解析来调用回调函数。&lt;/li&gt;
&lt;li&gt;在回调函数中，你可以解析网页响应并返回项目对象和请求对象或两者的迭代。这些请求也将包含一个回调，然后被 Scrapy 下载，然后有指定的回调处理。&lt;/li&gt;
&lt;li&gt;在回调函数中，你解析网站的内容，同程使用的是 Xpath 选择器（但是你也可以使用 BeautifuSoup, lxml 或其他任何你喜欢的程序），并生成解析的数据项。&lt;/li&gt;
&lt;li&gt;最后，从蜘蛛返回的项目通常会进驻到项目管道。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;5、项目管道 (Item Pipeline)&lt;/strong&gt;&lt;br /&gt;
 主要责任是负责处理有蜘蛛从网页中抽取的项目，他的主要任务是清晰、验证和存储数据。当页面被蜘蛛解析后，将被发送到项目管道，并经过几个特定的次序处理数据。每个项目管道的组件都是有一个简单的方法组成的 Python 类。他们获取了项目并执行他们的方法，同时他们还需要确定的是是否需要在项目管道中继续执行下一步或是直接丢弃掉不处理。&lt;br /&gt;
项目管道通常执行的过程有：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;清洗 HTML 数据&lt;/li&gt;
&lt;li&gt;验证解析到的数据（检查项目是否包含必要的字段）&lt;/li&gt;
&lt;li&gt;检查是否是重复数据（如果重复就删除）&lt;/li&gt;
&lt;li&gt;将解析到的数据存储到数据库中&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;6、下载器中间件 (Downloader Middlewares)&lt;/strong&gt;&lt;br /&gt;
 位于 Scrapy 引擎和下载器之间的钩子框架，主要是处理 Scrapy 引擎与下载器之间的请求及响应。它提供了一个自定义的代码的方式来拓展 Scrapy 的功能。下载中间器是一个处理请求和响应的钩子框架。他是轻量级的，对 Scrapy 尽享全局控制的底层的系统。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;7、蜘蛛中间件 (Spider Middlewares)&lt;/strong&gt;&lt;br /&gt;
 介于 Scrapy 引擎和蜘蛛之间的钩子框架，主要工作是处理蜘蛛的响应输入和请求输出。它提供一个自定义代码的方式来拓展 Scrapy 的功能。蛛中间件是一个挂接到 Scrapy 的蜘蛛处理机制的框架，你可以插入自定义的代码来处理发送给蜘蛛的请求和返回蜘蛛获取的响应内容和项目。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;8、调度中间件 (Scheduler Middlewares)&lt;/strong&gt;&lt;br /&gt;
 介于 Scrapy 引擎和调度之间的中间件，从 Scrapy 引擎发送到调度的请求和响应。他提供了一个自定义的代码来拓展 Scrapy 的功能。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;数据处理流程&lt;/strong&gt;&lt;br /&gt;
&lt;img data-src=&#34;image001.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;如图所示，显示的是 Scrapy 爬虫执行流程，绿线是数据流向，首先从初始 URL 开始，Scheduler 会将其交给 Downloader 进行下载，下载之后会交给 Spider 进行分析，Spider 分析出来的结果有两种：一种是需要进一步抓取的链接，例如之前分析的 “下一页” 的链接，这些东西会被传回 Scheduler；另一种是需要保存的数据，它们则被送到 Item Pipeline 那里，那是对数据进行后期处理（详细分析、过滤、存储等）的地方。另外，在数据流动的通道里还可以安装各种中间件，进行必要的处理。&lt;/p&gt;
&lt;p&gt;Scrapy 中的数据流由执行引擎控制，其过程如下:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;引擎打开一个网站 (open a domain)，找到处理该网站的 Spider 并向该 spider 请求第一个要爬取的 URL (s)。&lt;/li&gt;
&lt;li&gt;引擎从 Spider 中获取到第一个要爬取的 URL 并在调度器 (Scheduler) 以 Request 调度。&lt;/li&gt;
&lt;li&gt;引擎向调度器请求下一个要爬取的 URL。&lt;/li&gt;
&lt;li&gt;调度器返回下一个要爬取的 URL 给引擎，引擎将 URL 通过下载中间件 (请求 (request) 方向) 转发给下载器 (Downloader)。&lt;/li&gt;
&lt;li&gt;一旦页面下载完毕，下载器生成一个该页面的 Response, 并将其通过下载中间件 (返回 (response) 方向) 发送给引擎。&lt;/li&gt;
&lt;li&gt;引擎从下载器中接收到 Response 并通过 Spider 中间件 (输入方向) 发送给 Spider 处理。&lt;/li&gt;
&lt;li&gt;Spider 处理 Response 并返回爬取到的 Item 及 (跟进的) 新的 Request 给引擎。&lt;/li&gt;
&lt;li&gt;引擎将 (Spider 返回的) 爬取到的 Item 给 Item Pipeline，将 (Spider 返回的) Request 给调度器。&lt;/li&gt;
&lt;li&gt;(从第二步) 重复直到调度器中没有更多地 request，引擎关闭该网站&lt;/li&gt;
&lt;/ol&gt;
&lt;/font&gt;
&lt;h2 id=&#34;scrapy命令行工具&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#scrapy命令行工具&#34;&gt;#&lt;/a&gt; Scrapy 命令行工具&lt;/h2&gt;
&lt;font color=&#34;green&#34;&gt;
&lt;p&gt;Scrapy 是通过 scrapy 命令行工具进行控制的。这里我们称之为 “Scrapy tool” 以用来和子命令进行区分。对于子命令，我们称为 “command” 或者 “Scrapy commands”。Scrapy tool 针对不同的目的提供了多个命令，每个命令支持不同的参数和选项&lt;/p&gt;
&lt;/font&gt;
&lt;h2 id=&#34;默认的scrapy-项目结构&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#默认的scrapy-项目结构&#34;&gt;#&lt;/a&gt; 默认的 Scrapy 项目结构&lt;/h2&gt;
&lt;font color=&#34;DeepSkyBlue&#34;&gt;
&lt;p&gt;在开始对命令行工具以及子命令的探索前，让我们首先了解一下 Scrapy 的项目的目录结构。虽然可以被修改，但所有的 Scrapy 项目默认有类似于下边的文件结构:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;scrapy.cfg
    myproject/
        __init__.py
        items.py
        middlewares.py
        pipelines.py
        settings.py
        spiders/
            __init__.py
            spider1.py
            spider2.py
            ...
&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;
&lt;li&gt;scrapy.cfg&lt;br /&gt;
 存放的目录被认为是项目的根目录。该文件中包含 python 模块名的字段定义了项目的设置。&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cDovL2l0ZW1zLnB5&#34;&gt;items.py&lt;/span&gt;&lt;br /&gt;
 该文件中包含了 scrapy 数据容器模型代码。&lt;br /&gt;
Item 对象是种简单的容器，保存了爬取到得数据。其提供了类似于词典 (dictionary-like) 的 API 以及用于声明可用字段的简单语法。&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cDovL21pZGRsZXdhcmVzLnB5&#34;&gt;middlewares.py&lt;/span&gt;&lt;br /&gt;
 该文件中包含下载器中间件和爬虫中间件模型代码。&lt;br /&gt;
下载器中间件是介于 Scrapy 的 request/response 处理的钩子框架。是用于全局修改 Scrapy request 和 response 的一个轻量、底层的系统。&lt;br /&gt;
爬虫中间件是介入到 Scrapy 的 spider 处理机制的钩子框架，您可以添加代码来处理发送给 Spiders 的 response 及 spider 产生的 item 和 request。。&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cDovL3BpcGVsaW5lcy5weQ==&#34;&gt;pipelines.py&lt;/span&gt;&lt;br /&gt;
 每个管道组件是实现了简单方法的 Python 类。&lt;br /&gt;
他们接收到 Item 并通过它执行一些行为，同时也决定此 Item 是否继续通过后续的管道组件，或是被丢弃而不再进行处理。&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cDovL3NldHRpbmdzLnB5&#34;&gt;settings.py&lt;/span&gt;&lt;br /&gt;
Scrapy 设定 (settings) 提供了定制 Scrapy 组件的方法。&lt;br /&gt;
您可以控制包括核心 (core)，插件 (extension)，pipeline 及 spider 组件。&lt;/li&gt;
&lt;/ol&gt;
&lt;/font&gt;
&lt;h1 id=&#34;编写第一个scrapy爬虫&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#编写第一个scrapy爬虫&#34;&gt;#&lt;/a&gt; 编写第一个 Scrapy 爬虫&lt;/h1&gt;
&lt;font color=&#34;BlueViolet&#34;&gt;
&lt;p&gt;任务:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;创建一个 Scrapy 项目&lt;/li&gt;
&lt;li&gt;定义提取的 Item&lt;/li&gt;
&lt;li&gt;编写爬取网站的 spider 并提取 Item&lt;/li&gt;
&lt;li&gt;编写 Item Pipeline 来存储提取到的 Item (即数据)&lt;/li&gt;
&lt;/ol&gt;
&lt;/font&gt;
&lt;h2 id=&#34;创建项目&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#创建项目&#34;&gt;#&lt;/a&gt; 创建项目&lt;/h2&gt;
&lt;font color=&#34;BlueViolet&#34;&gt;
&lt;p&gt;在开始爬取之前，您必须创建一个新的 Scrapy 项目。&lt;br /&gt;
进入您打算存储代码的目录中，运行下列命令: &lt;code&gt;scrapy startproject tutorial&lt;/code&gt; &lt;br /&gt;
 该命令将会创建包含下列内容的 tutorial 目录:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tutorial/
    scrapy.cfg
    tutorial/
        __init__.py
        items.py
        pipelines.py
        settings.py
        spiders/
            __init__.py
            ...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这些文件分别是:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;scrapy.cfg: 项目的配置文件&lt;/li&gt;
&lt;li&gt;tutorial/: 该项目的 python 模块。之后您将在此加入代码。&lt;/li&gt;
&lt;li&gt;tutorial/items.py: 项目中的 item 文件。&lt;/li&gt;
&lt;li&gt;tutorial/pipelines.py: 项目中的 pipelines 文件。&lt;/li&gt;
&lt;li&gt;tutorial/settings.py: 项目的设置文件。&lt;/li&gt;
&lt;li&gt;tutorial/spiders/: 放置 spider 代码的目录&lt;/li&gt;
&lt;/ul&gt;
&lt;/font&gt;
&lt;h2 id=&#34;定义item&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#定义item&#34;&gt;#&lt;/a&gt; 定义 Item&lt;/h2&gt;
&lt;font color=&#34;BlueViolet&#34;&gt;
&lt;p&gt;Item 是保存爬取到的数据的容器；其使用方法和 python 字典类似，并且提供了额外保护机制来避免拼写错误导致的未定义字段错误。&lt;br /&gt;
类似在 ORM 中做的一样，您可以通过创建一个 scrapy.Item 类，并且定义类型为 scrapy.Field 的类属性来定义一个 Item。(如果不了解 ORM, 不用担心，您会发现这个步骤非常简单)&lt;br /&gt;
 首先根据需要从 dmoz.org 获取到的数据对 item 进行建模。我们需要从 dmoz 中获取名字，url，以及网站的描述。对此，在 item 中定义相应的字段。编辑 tutorial 目录中的 items.py 文件。&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;figcaption data-lang=&#34;python&#34;&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td data-num=&#34;1&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;items&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;py&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;2&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;3&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;span class=&#34;token keyword&#34;&gt;import&lt;/span&gt; scrapyclass &lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;4&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;5&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;6&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;DmozItem&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;scrapy&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;Item&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;:&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;7&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    title&lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt;scrapy&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;Field&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;8&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    link&lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt;scrapy&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;Field&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;9&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    desc&lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt;scrapy&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;Field&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;代码一开始这看起来可能有点复杂，但是通过定义 item，您可以很方便的使用 Scrapy 的其他方法。而这些方法需要知道您的 item 的定义。&lt;/p&gt;
&lt;/font&gt;
&lt;h2 id=&#34;spider爬虫&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#spider爬虫&#34;&gt;#&lt;/a&gt; Spider 爬虫&lt;/h2&gt;
&lt;font color=&#34;BlueViolet&#34;&gt;
&lt;p&gt;Spider 是用户编写用于从单个网站 (或者一些网站) 爬取数据的类。&lt;br /&gt;
其包含了一个用于下载的初始 URL，如何跟进网页中的链接以及如何分析页面中的内容，提取生成 item 的方法。&lt;/p&gt;
&lt;p&gt;为了创建一个 Spider，您必须继承 scrapy.Spider 类，且定义以下三个属性:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;name: 用于区别 Spider。该名字必须是唯一的，您不可以为不同的 Spider 设定相同的名字。&lt;/li&gt;
&lt;li&gt;start_urls: 包含了 Spider 在启动时进行爬取的 url 列表。因此，第一个被获取到的页面将是其中之一。后续的 URL 则从初始的 URL 获取到的数据中提取。&lt;/li&gt;
&lt;li&gt;parse () 是 spider 的一个方法。被调用时，每个初始 URL 完成下载后生成的 Response 对象将会作为唯一的参数传递给该函数。该方法负责解析返回的数据 (response data)，提取数据 (生成 item) 以及生成需要进一步处理的 URL 的 Request 对象。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;也可以使用命令行创建一个 Spider。比如要生成 Quotes 这个 Spider，可以执行如下命令：&lt;br /&gt;
 &lt;code&gt;cd 项目目录&lt;/code&gt; &lt;br /&gt;
 &lt;code&gt;scrapy genspider quotes quotes.toscrape.com&lt;/code&gt; &lt;br /&gt;
 语法格式&lt;br /&gt;
 &lt;code&gt;scrapy genspider [options] &amp;lt;name&amp;gt; &amp;lt;domain&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;以下为我们的第一个 Spider 代码，保存在 tutorial/spiders 目录下的 dmoz_spider.py 文件中，如 Code 3-21 所示:&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;figcaption data-lang=&#34;python&#34;&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td data-num=&#34;1&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;span class=&#34;token comment&#34;&gt;# -*-coding: utf-8 -*-&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;2&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;span class=&#34;token keyword&#34;&gt;import&lt;/span&gt; scrapyclass &lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;3&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;4&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;5&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;DmozSpider&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;scrapy&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;Spider&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;:&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;6&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    name &lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;token string&#34;&gt;&#39;dmoz&#39;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;7&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    allowed_domains &lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;token punctuation&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;token string&#34;&gt;&#39;dmoz.org&#39;&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;]&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;8&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    start_urls &lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;token punctuation&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;token string&#34;&gt;&#39;http://www.dmoz.org/Computers/Programming/Langurages/Python/Books&#39;&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;,&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;9&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    &lt;span class=&#34;token string&#34;&gt;&#39;http://www.dmoz.org/Computers/Programming/Langurages/Python/Resources&#39;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;10&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    &lt;span class=&#34;token punctuation&#34;&gt;]&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;11&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;12&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;13&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    &lt;span class=&#34;token keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;token function&#34;&gt;parse&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;self&lt;span class=&#34;token punctuation&#34;&gt;,&lt;/span&gt; response&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;:&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;14&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    filename&lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt;response&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;split&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token string&#34;&gt;&#34;/&#34;&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;token operator&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;token number&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;]&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;15&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    &lt;span class=&#34;token keyword&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;token builtin&#34;&gt;open&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;filename&lt;span class=&#34;token punctuation&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;token string&#34;&gt;&#39;wb&#39;&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;token keyword&#34;&gt;as&lt;/span&gt; f&lt;span class=&#34;token punctuation&#34;&gt;:&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;16&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;        f&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;write&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;response&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;body&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/font&gt;
&lt;h2 id=&#34;爬虫爬取&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#爬虫爬取&#34;&gt;#&lt;/a&gt; 爬虫爬取&lt;/h2&gt;
&lt;font color=&#34;BlueViolet&#34;&gt;
&lt;p&gt;进入项目的根目录，执行下列命令启动 spider: &lt;code&gt;scrapy crawl homeweather&lt;/code&gt;&lt;/p&gt;
&lt;/font&gt;
&lt;h2 id=&#34;紧急&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#紧急&#34;&gt;#&lt;/a&gt; 紧急&lt;/h2&gt;
&lt;p&gt;学校要提前放假，考试也提前了。。&lt;br /&gt;
抓紧时间备考了&lt;/p&gt;
&lt;p&gt;考试后再总结&lt;/p&gt;
</content>
        <category term="scrapy" />
        <updated>2020-12-28T09:47:19.000Z</updated>
    </entry>
</feed>
